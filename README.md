# An Ethical AI Imperative
 
This repository hosts an data journalism piece focused on the intersection of AI and ethical hiring practices. It delves into the ramifications of biases in AI models, inspired by the work of Timnit Gebru and recent studies such as those by Leon Yin, highlighting their impact on marginalized groups and the need for ethical AI frameworks in employmen

<b>Links to studies referenced: </b> 
<ul> 
 <li><a href="https://dl.acm.org/doi/10.1145/3442188.3445922">"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?"</a> by Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, Shmargaret Shmitchell</li>
 <li><a href = "https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcwOTg1NjE4NCwiZXhwIjoxNzEwNDYwOTg0LCJhcnRpY2xlSWQiOiJTQTA1Q1FUMEFGQjQwMCIsImJjb25uZWN0SWQiOiI4QkY3REVFODZERTk0QjdEOEVDRDA1OEQ4RUJDQzAzMyJ9.q4dHdWWVcJO9PMKhwQ-IF5BfvVNVmPAX8hWNyrtwSYY"> Leon Yin's Bloomberg investigation on GPT's racial bias.</a></li>
 <li> <a href = "https://www.sciencedirect.com/science/article/pii/S2949882124000148?via%3Dihub"> Computer says ‘no’: Exploring systemic bias in ChatGPT using an audit approach</a> by Louis Lippens</li>
</ul>
